{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c35382-16ea-4c42-9d64-5888d7bc4d45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import argparse\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import sys\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1424b4-388a-43a6-a404-f2560e77a9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_if_not_exists(folder_name) :\n",
    "    if not os.path.exists(folder_name) :\n",
    "        os.makedirs(folder_name)\n",
    "\n",
    "def get_data() :\n",
    "    '''\n",
    "    Returns Tx3 values of stock prices\n",
    "    -------------------------------------------\n",
    "    col0 - AAPL\n",
    "    col1 - MSI\n",
    "    col2 - SBUX\n",
    "    '''\n",
    "    df = pd.read_csv('aapl_msi_sbux.csv')\n",
    "    return df.values\n",
    "\n",
    "def get_scalar(env):  #to make it more accurate, run it for multiple epis\n",
    "    states = []\n",
    "    for _ in range(env.n_step):\n",
    "        action = np.random.choice(env.action_space)\n",
    "        state, reward, done, info = env.step(action)\n",
    "        states.append(state)\n",
    "        if done :\n",
    "            break\n",
    "        \n",
    "    scalar = StandardScaler()\n",
    "    scalar.fit(states)\n",
    "    return scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a624d-8972-464e-b253-a660767f75b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LinRegression :\n",
    "    def __init__(self, input_dim, n_action, learning_rate=0.01, momentum=0.9) :\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        \n",
    "        self.Wa = np.random.randn(input_dim, n_action) / np.sqrt(input_dim)\n",
    "        self.ba = np.zeros(n_action)\n",
    "        \n",
    "        #momentum terms\n",
    "        self.vW = 0\n",
    "        self.vb = 0\n",
    "        \n",
    "        self.losses = []\n",
    "        \n",
    "    def predict(self, X) :\n",
    "        assert(len(X.shape) == 2) \n",
    "        return X @ self.Wa + self.ba\n",
    "    \n",
    "    def sgd(self, X, Y) :\n",
    "        assert(len(X.shape) == 2)\n",
    "        \n",
    "        #total num of values in Y\n",
    "        num_values = np.prod(Y.shape)\n",
    "        \n",
    "        Yhat = self.predict(X)\n",
    "        gW = 2 * X.T.dot(Yhat - Y) / num_values\n",
    "        gb = 2 * (Yhat - Y).sum(axis=0) / num_values\n",
    "        \n",
    "        #updating momentum terms\n",
    "        self.vW = self.momentum * self.vW - self.learning_rate * gW\n",
    "        self.vb = self.momentum * self.vb - self.learning_rate * gb\n",
    "        \n",
    "        #updating weights\n",
    "        self.Wa = self.Wa + self.vW\n",
    "        self.ba = self.ba + self.vb\n",
    "        \n",
    "        mse = np.mean((Yhat - Y)**2)\n",
    "        self.losses.append(mse)\n",
    "        \n",
    "    def load_weights(self, filepath) :\n",
    "        npz = np.load(filepath)\n",
    "        self.Wa = npz['Wa']\n",
    "        self.ba = npz['ba']\n",
    "        \n",
    "    def save_weights(self, filepath) :\n",
    "        np.savez(filepath, Wa=self.Wa, ba=self.ba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eae31-ec54-4b10-8b05-e595b0df9211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(self, data, initial_investment=20000) :\n",
    "        self.stock_price_history = data\n",
    "        self.initial_investment = initial_investment\n",
    "        \n",
    "        self.n_step, self.n_stocks = self.stock_price_history.shape\n",
    "\n",
    "        \n",
    "        self.cur_step = None #pointer\n",
    "        self.stock_owned = None\n",
    "        self.stock_price = None\n",
    "        self.cash_in_hand = None\n",
    "        \n",
    "        self.action_space = np.arange(3**self.n_stocks)\n",
    "        \n",
    "        self.action_list = list(map(list, itertools.product([0, 1, 2], repeat=3)))\n",
    "        \n",
    "        self.state_dim = self.n_stocks * 2 + 1\n",
    "        self.reset()\n",
    "        \n",
    "        \n",
    "    def reset(self) :\n",
    "        self.cur_step = 0\n",
    "        self.stock_owned = np.zeros(self.n_stocks)\n",
    "        self.stock_price = self.stock_price_history[self.cur_step]\n",
    "        self.cash_in_hand = self.initial_investment\n",
    "        return self._get_obs()\n",
    "    \n",
    "    def step(self, action) :\n",
    "        assert action in self.action_space\n",
    "        \n",
    "        old_portfolio_val = self._get_val()\n",
    "        \n",
    "        self.cur_step += 1\n",
    "        self.stock_price = self.stock_price_history[self.cur_step]\n",
    "        \n",
    "        #performing the trade\n",
    "        self._trade(action)\n",
    "        \n",
    "        new_portfolio_val = self._get_val()\n",
    "        \n",
    "        #calculating reward\n",
    "        reward = new_portfolio_val - old_portfolio_val\n",
    "        \n",
    "        #checking done flag\n",
    "        done = self.cur_step == (self.n_step - 1)\n",
    "        \n",
    "        #storing the current portfolio value\n",
    "        info = {'cur_val' : new_portfolio_val}\n",
    "        \n",
    "        return self._get_obs(), reward, done, info\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        obs = np.empty(self.state_dim, dtype=np.float32)\n",
    "        obs[:self.n_stocks] = self.stock_owned\n",
    "        obs[self.n_stocks:self.n_stocks*2] = self.stock_price\n",
    "        obs[-1] = self.cash_in_hand\n",
    "        return obs\n",
    "    \n",
    "    def _get_val(self) :\n",
    "        return self.stock_owned @ self.stock_price + self.cash_in_hand\n",
    "    \n",
    "    def _trade(self, action) :\n",
    "        '''\n",
    "        Trades the action in the environment\n",
    "        ----------------------------------------\n",
    "        0 - sell\n",
    "        1 - hold\n",
    "        2 - buy\n",
    "        '''\n",
    "        action_vec = self.action_list[action]\n",
    "        # sell_index = [] # stores index of stocks we want to sell\n",
    "        # buy_index = [] # stores index of stocks we want to buy\n",
    "        # for i, a in enumerate(action_vec):\n",
    "        #     if a == 0:\n",
    "        #         sell_index.append(i)\n",
    "        #     elif a == 2:\n",
    "        #         buy_index.append(i)\n",
    "        sell_index = np.argwhere(np.array(action_vec) == 0).ravel()\n",
    "        buy_index = np.argwhere(np.array(action_vec) == 2).ravel()\n",
    "        \n",
    "        if len(sell_index) > 0 :\n",
    "            for i in sell_index :\n",
    "                self.cash_in_hand += self.stock_price[i] * self.stock_owned[i]\n",
    "                self.stock_owned[i] = 0\n",
    "        if len(buy_index) > 0 :\n",
    "            for i in buy_index :\n",
    "                if self.cash_in_hand > self.stock_price[i] :\n",
    "                    self.cash_in_hand -= self.stock_price[i]\n",
    "                    self.stock_owned[i] += 1\n",
    "                else :\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5153b18-2dac-4775-a914-6c422347f72f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DQNAgent(object) :\n",
    "    def __init__(self, state_size, action_size) :\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0 #exploration rate\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.model = LinRegression(state_size, action_size)\n",
    "        \n",
    "    def act(self, state) :\n",
    "        if np.random.rand() <= self.epsilon :\n",
    "            return np.random.choice(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])\n",
    "    \n",
    "    def train(self, state, action, reward, next_state, done) :\n",
    "        if done:\n",
    "            target = reward\n",
    "        else :\n",
    "            target = reward + self.gamma * np.amax(self.model.predict(next_state), axis=1)\n",
    "        \n",
    "        target_full = self.model.predict(state)\n",
    "        print(f'Target', target)\n",
    "        target_full[0, action] = target.item()\n",
    "        \n",
    "        self.model.sgd(state, target_full)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min :\n",
    "            self.epsilon *= self.epsilon_decay\n",
    "            \n",
    "    def load(self, name) :\n",
    "        self.model.load_weights(name)\n",
    "        \n",
    "    def save(self, name) :\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb7550f-97d5-44f4-9bcb-6907110b2e28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def play_one_epsiode(agent, env, is_train, scaler) : \n",
    "    state = env.reset()\n",
    "    # scaler = StandardScaler()\n",
    "    state = scaler.transform([state])\n",
    "    done = False\n",
    "    while not done :\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        next_state = scaler.transform([next_state])\n",
    "        if is_train == 'train' :\n",
    "            agent.train(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        \n",
    "    return info['cur_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3baf09-75ea-4ef8-8670-a8ecdd83f606",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_info(episode_number, total_episodes, dct=None):\n",
    "    arrow_length = 30\n",
    "    progress = int((episode_number / total_episodes) * arrow_length)\n",
    "    progress_bar = \"=\" * progress + \">\"\n",
    "    info_string = \"\\rEpisode: [{:<30}] {}/{}\".format(progress_bar, episode_number, total_episodes)\n",
    "    if dct is not None:\n",
    "        info_string += \", {}\".format(dct)\n",
    "    sys.stdout.write(info_string.ljust(100))  # Adjust the total length as needed\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac661c-079b-49e6-8a76-7845817a2a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args) :\n",
    "    if __name__ == '__main__' :\n",
    "        #config\n",
    "        models_folder = 'linear_rl_trader_models'\n",
    "        rewards_folder = 'linear_rl_trader_rewards'\n",
    "        num_epsiodes = 1\n",
    "        batch_size  = 32\n",
    "        initial_investment = 20000\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('-m', '--mode', type=str, required=True, help='either \"train\" or \"test\"')\n",
    "        args = parser.parse_args(args)\n",
    "\n",
    "        make_if_not_exists(models_folder)\n",
    "        make_if_not_exists(rewards_folder)\n",
    "\n",
    "        data = get_data()\n",
    "        n_timesteps, n_stocks = data.shape\n",
    "\n",
    "        n_train = n_timesteps // 2\n",
    "\n",
    "        train_data = data[:n_train]\n",
    "        test_data = data[n_train:]\n",
    "\n",
    "        env = Environment(train_data, initial_investment)\n",
    "        state_size = env.state_dim\n",
    "        action_size = len(env.action_space)\n",
    "        agent = DQNAgent(state_size, action_size)\n",
    "        scaler = get_scalar(env)\n",
    "\n",
    "        portfolio_value = []\n",
    "\n",
    "        if args.mode == 'test' :\n",
    "            with open(os.path.join(models_folder, 'scalar.pkl'), 'rb') as f:\n",
    "                scalar = pickle.load(f)\n",
    "\n",
    "            env = Environment(test_data, initial_investment)\n",
    "\n",
    "            agent.epsilon = 0.01\n",
    "\n",
    "            agent.load(os.path.join(models_folder, 'linear.npz'))\n",
    "\n",
    "        for e in range(num_epsiodes) :\n",
    "            t0 = datetime.now()\n",
    "            val = play_one_epsiode(agent, env, args.mode, scaler)\n",
    "            dt = datetime.now() - t0\n",
    "            print_info(e+1, num_epsiodes, {\"value\" : f'{val:.2f}', \"duration\" : f'{(dt.total_seconds() * 1000):.2f} ms'})\n",
    "            # print(f'Epsiode: {e + 1} / {num_epsiodes}, value: {val:.2f}, duration: [{dt}]ms')\n",
    "            portfolio_value.append(val)\n",
    "\n",
    "        if args.mode == 'train' :\n",
    "            agent.save(os.path.join(models_folder, 'linear.npz'))\n",
    "\n",
    "            with open(os.path.join(models_folder, 'scalar.pkl'), 'wb') as f:\n",
    "                pickle.dump(scaler, f)\n",
    "\n",
    "            plt.plot(agent.model.losses)\n",
    "            plt.show()\n",
    "            \n",
    "        # save portfolio value for each episode\n",
    "        np.save(f'{rewards_folder}/{args.mode}.npy', portfolio_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255faa8c-b9f9-419c-a909-125beb37cde5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main(['--mode', 'train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2904d95-6dba-45e8-be2a-bd4d4e9d37b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
